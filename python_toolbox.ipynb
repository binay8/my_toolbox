{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Python Style Guide/Naming Convention</h1>\n",
    "<p><b>Use following table</b></p>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Action</th>\n",
    "    <th>Naming Convention</th> \n",
    "    <th>Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Package/Module Name</td>\n",
    "    <td>lowercasename</td>\n",
    "    <td>Prefably all-lowercase name. Underscore to seperate words accepted</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Class Name</td>\n",
    "    <td>CapWord</td>\n",
    "    <td>Normally CapWord convention needs to be followed. Exceptions exists </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Functions</td>\n",
    "    <td>lowercase_undrscor_sprated</td>\n",
    "    <td>Function Names should be lowercase, with words separated by underscores as necessary to improve readability</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Variables</td>\n",
    "    <td>lowercase_undrscor_sprated</td>\n",
    "    <td>Variables Name should be lowercase, with words separated by underscores as necessary to improve readability</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Function and Method Argument</td>\n",
    "    <td>Use \"self\" for first argumnet to instance method. Use \"cls\" for the first argument to class method</td>\n",
    "    <td>If a function argument's name clashes with a reserved keyword, it is generally better to append a single trailing underscore rather than use an abbreviation or spelling corruption. Thus class_ is better than clss. </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Method Name and Instance variable</td>\n",
    "    <td>lowercase_undrscor_sprated</td>\n",
    "    <td>Exceptions may apply</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Constant</td>\n",
    "    <td>ALLCAP_UNDRSCOR_SPRATED</td>\n",
    "    <td>Constants are usually defined on a module level and written in all capital letters with underscores separating words.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p><b>For more on Style Guide and Naming convention click link below</b></p>\n",
    "<p><a href=\"https://www.python.org/dev/peps/pep-0008/#package-and-module-names\">PEP 8--Style Guide for Python</a></p>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading CSV and excel files from different sources</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:\\\\Users\\\\username\\\\.....\\\\filename.csv' does not exist: b'C:\\\\Users\\\\username\\\\.....\\\\filename.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8bcc7392b559>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\username\\.....\\filename.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:\\\\Users\\\\username\\\\.....\\\\filename.csv' does not exist: b'C:\\\\Users\\\\username\\\\.....\\\\filename.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = r'C:\\Users\\username\\.....\\filename.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "github_url = 'https://raw.githubusercontent.com/username/...../filename.csv'\n",
    "df = pd.read_csv(github_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Azure data lake store file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_id = 'xxx-xx-xxxx-xx-xxxx'\n",
    "application_key = 'xxxccxcs@#dsgfxxx'\n",
    "application_id = 'xxxx-xxxx-xx-xx-xxxxx'\n",
    "\n",
    "adls_cred = lib.auth(tenant_id = directory_id, client_secret= application_key, client_id= application_id)\n",
    "adls_name = \"storename\"\n",
    "adls_client = core.AzureDLFileSystem(adls_cred, store_name= adls_name)\n",
    "\n",
    "f = adls_client.open('.../../.../filename.csv', 'rb') # Path similar to local directory\n",
    "df = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>For more on reading csv and excel files go to following documentations </b></p>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\">pandas.read_csv</a></p>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\">pandas.read_excel</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating DataFrame</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_col</th>\n",
       "      <th>val_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jacob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Jingleheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Schmidt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_col       val_col\n",
       "0       1          John\n",
       "1       2         Jacob\n",
       "2       3  Jingleheimer\n",
       "3       4       Schmidt"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample_dict = {'id_col':[1,2,3,4], 'val_col': ['John', 'Jacob', 'Jingleheimer', 'Schmidt']}\n",
    "df_from_dict = pd.DataFrame(data= sample_dict) \n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>Jacob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Jingleheimer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id age          name\n",
       "0  1  12          John\n",
       "1  4  13         Jacob\n",
       "2  7  10  Jingleheimer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_from_numpy = pd.DataFrame(np.array([[1, 12, 'John'], [4, 13, 'Jacob'], [7, 10, 'Jingleheimer']]),\n",
    "                             columns=['id', 'age', 'name'])\n",
    "df_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Drop column by Column Name</h1>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop\">pandas.DataFrame.drop</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "\n",
      "   id          name  age\n",
      "0   1          John    4\n",
      "1   2         Jacob    4\n",
      "2   3  Jingleheimer    3\n",
      "3   4       Schmidt    3\n",
      "After Drop\n",
      "\n",
      "   id          name\n",
      "0   1          John\n",
      "1   2         Jacob\n",
      "2   3  Jingleheimer\n",
      "3   4       Schmidt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample_dict = {'id':np.arange(start = 1, stop = 5), \n",
    "               'name': ['John', 'Jacob', 'Jingleheimer', 'Schmidt'],\n",
    "               'age':np.random.randint(low=0, high = 5, size = 4)}\n",
    "df_from_dict = pd.DataFrame(data= sample_dict) \n",
    "df_col_dropped = df_from_dict.drop(['age'] , axis =1)\n",
    "\n",
    "print(\"Before\\n\")\n",
    "print(df_from_dict.head())\n",
    "\n",
    "print(\"After Drop\\n\")\n",
    "print(df_col_dropped.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Drop multiple columns by Name</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "\n",
      "   id          name  age  height\n",
      "0   1          John    1      24\n",
      "1   2         Jacob    2      25\n",
      "2   3  Jingleheimer    4      25\n",
      "3   4       Schmidt    1      20\n",
      "\n",
      "After Drop\n",
      "\n",
      "   id          name\n",
      "0   1          John\n",
      "1   2         Jacob\n",
      "2   3  Jingleheimer\n",
      "3   4       Schmidt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample_dict = {'id':np.arange(start = 1, stop = 5), \n",
    "               'name': ['John', 'Jacob', 'Jingleheimer', 'Schmidt'],\n",
    "               'age':np.random.randint(low=0, high = 5, size = 4),\n",
    "              'height': np.random.randint(20,30,size=4)}\n",
    "df_from_dict = pd.DataFrame(data= sample_dict) \n",
    "\n",
    "df_col_dropped = df_from_dict.drop(['age', 'height'] , axis =1)\n",
    "\n",
    "print(\"Before\\n\")\n",
    "print(df_from_dict.head())\n",
    "\n",
    "print(\"\\nAfter Drop\\n\")\n",
    "print(df_col_dropped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Filter DF by value(s) in column</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "\n",
      "   id          name  age  height\n",
      "0   1          John    1      27\n",
      "1   2         Jacob    1      24\n",
      "2   3  Jingleheimer    1      24\n",
      "3   4       Schmidt    3      23\n",
      "\n",
      "After\n",
      "\n",
      "   id   name  age  height\n",
      "0   1   John    1      27\n",
      "1   2  Jacob    1      24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample_dict = {'id':np.arange(start = 1, stop = 5), \n",
    "               'name': ['John', 'Jacob', 'Jingleheimer', 'Schmidt'],\n",
    "               'age':np.random.randint(low=0, high = 5, size = 4),\n",
    "              'height': np.random.randint(20,30,size=4)}\n",
    "df = pd.DataFrame(data= sample_dict) \n",
    "\n",
    "val_list = ['John', 'Jacob']\n",
    "\n",
    "filtered_df = df[df['name'].isin(val_list)]\n",
    "print(\"Before\\n\")\n",
    "print(df)\n",
    "\n",
    "print('\\nAfter\\n')\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>File System Operation in Azure Data Lake Store</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_id = 'xxx-xx-xxxx-xx-xxxx'\n",
    "application_key = 'xxxccxcs@#dsgfxxx'\n",
    "application_id = 'xxxx-xxxx-xx-xx-xxxxx'\n",
    "\n",
    "adls_cred = lib.auth(tenant_id = directory_id, client_secret= application_key, client_id= application_id)\n",
    "adls_name = \"storename\"\n",
    "adls_client = core.AzureDLFileSystem(adls_cred, store_name= adls_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adls_client.mkdir('/newfolder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a file in Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multithread.ADLUploader(adls_client, lpath=\"C:\\\\.....\\\\file.csv\", rpath=\"/newfolder/file.csv\", nthreads=64, overwrite=True, buffersize=4194304, blocksize=4194304)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a file from Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multithread.ADLDownloader(adls_client, lpath='C:\\\\user.....\\\\mysamplefile.txt.out', rpath='/newfolder/mysamplefile.txt', nthreads=64, overwrite=True, buffersize=4194304, blocksize=4194304)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsFileSystemClient.rm('/newfolder', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Convert DataFrame to csv</h1>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\">pandas.DataFrame.to_csv</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample_dict = {'id':np.arange(start = 1, stop = 5), \n",
    "               'name': ['John', 'Jacob', 'Jingleheimer', 'Schmidt'],\n",
    "               'age':np.random.randint(low=0, high = 5, size = 4),\n",
    "              'height': np.random.randint(20,30,size=4)}\n",
    "df = pd.DataFrame(data= sample_dict) \n",
    "\n",
    "output_path = r'C:\\User\\...\\...\\filename.csv'\n",
    "df.to_csv(output_path, index= False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Combining multiple DataFrames </h1>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html?highlight=concat#pandas.concat\">pandas.concat</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending rows between two or more DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id   name\n",
      "0  1   john\n",
      "1  2  jacob\n",
      "\n",
      "df2\n",
      "   id          name\n",
      "0  3  Jingleheimer\n",
      "1  4       Schmidt\n",
      "\n",
      "After concatening two dataframes\n",
      "   id          name\n",
      "0  1          john\n",
      "1  2         jacob\n",
      "2  3  Jingleheimer\n",
      "3  4       Schmidt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john'], [2,'jacob']]),\n",
    "                  columns=['id','name'])\n",
    "df2 = pd.DataFrame(np.array([[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "\n",
    "print('\\nAfter concatening two dataframes\\n',co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames when only some attributes match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id   name age\n",
      "0  1   john   5\n",
      "1  2  jacob   2\n",
      "\n",
      "df2\n",
      "   id          name\n",
      "0  3  Jingleheimer\n",
      "1  4       Schmidt\n",
      "\n",
      "Compare two dataframes. df1 has 3 attributes. df2 is missing age\n",
      "\n",
      "After concatening two dataframes\n",
      "   id          name  age\n",
      "0  1          john    5\n",
      "1  2         jacob    2\n",
      "0  3  Jingleheimer  NaN\n",
      "1  4       Schmidt  NaN\n",
      "\n",
      "The output will add NaN for age attrubute\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john',5], [2,'jacob',2]]),\n",
    "                  columns=['id','name','age'])\n",
    "df2 = pd.DataFrame(np.array([[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "\n",
    "combined_df = pd.concat([df1, df2], sort=False)\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "print('\\nCompare two dataframes. df1 has 3 attributes. df2 is missing age')\n",
    "\n",
    "print('\\nAfter concatening two dataframes\\n',combined_df)\n",
    "print('\\nThe output will add NaN for age attrubute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine DataFrames and return only attrubutes that are shared by both DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id   name age\n",
      "0  1   john   5\n",
      "1  2  jacob   2\n",
      "\n",
      "df2\n",
      "   id          name\n",
      "0  3  Jingleheimer\n",
      "1  4       Schmidt\n",
      "\n",
      "Compare two dataframes. df1 has 3 attributes. df2 is missing age\n",
      "\n",
      "After concatening two dataframes\n",
      "   id          name\n",
      "0  1          john\n",
      "1  2         jacob\n",
      "0  3  Jingleheimer\n",
      "1  4       Schmidt\n",
      "\n",
      "The output ignores the age attribute as the second dataframe is missing that attribute\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john',5], [2,'jacob',2]]),\n",
    "                  columns=['id','name','age'])\n",
    "df2 = pd.DataFrame(np.array([[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "\n",
    "combined_df = pd.concat([df1, df2], join= 'inner')\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "print('\\nCompare two dataframes. df1 has 3 attributes. df2 is missing age')\n",
    "\n",
    "print('\\nAfter concatening two dataframes\\n',combined_df)\n",
    "print('\\nThe output ignores the age attribute as the second dataframe is missing that attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Dataframes horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id          name\n",
      "0  1          john\n",
      "1  2         jacob\n",
      "2  3  Jingleheimer\n",
      "3  4       Schmidt\n",
      "\n",
      "df2\n",
      "   age  gender\n",
      "0   5    male\n",
      "1   4    male\n",
      "2   3    male\n",
      "3   6  female\n",
      "\n",
      "After concatening two dataframes\n",
      "   id          name age  gender\n",
      "0  1          john   5    male\n",
      "1  2         jacob   4    male\n",
      "2  3  Jingleheimer   3    male\n",
      "3  4       Schmidt   6  female\n",
      "\n",
      "Based on the concatnation the new attributes from df2 are added horizontally\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john'], [2,'jacob'],[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "df2 = pd.DataFrame(np.array([[5,'male'],[4,'male'],[3,'male'],[6,'female']]),\n",
    "                  columns=['age','gender'])\n",
    "\n",
    "combined_df = pd.concat([df1, df2], axis=1)\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "\n",
    "print('\\nAfter concatening two dataframes\\n',combined_df)\n",
    "print('\\nBased on the concatnation the new attributes from df2 are added horizontally')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Set Index from column</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before\n",
      "     id          name  age  height\n",
      "0  100          John    2      20\n",
      "1  101         Jacob    3      25\n",
      "2  102  Jingleheimer    4      23\n",
      "3  103       Schmidt    1      24\n",
      "\n",
      "After\n",
      "              name  age  height\n",
      "id                            \n",
      "100          John    2      20\n",
      "101         Jacob    3      25\n",
      "102  Jingleheimer    4      23\n",
      "103       Schmidt    1      24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample_dict = {'id':np.arange(start = 100, stop = 104, step = 1), \n",
    "               'name': ['John', 'Jacob', 'Jingleheimer', 'Schmidt'],\n",
    "               'age':np.random.randint(low=0, high = 5, size = 4),\n",
    "              'height': np.random.randint(20,30,size=4)}\n",
    "df = pd.DataFrame(data= sample_dict) \n",
    "print('\\nBefore\\n',df)\n",
    "print('\\nAfter\\n',df.set_index('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Joining DataFrames</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id          name\n",
      "0  1          john\n",
      "1  2         jacob\n",
      "2  3  Jingleheimer\n",
      "3  4       Schmidt\n",
      "\n",
      "df2\n",
      "   id age  gender\n",
      "0  1   5    male\n",
      "1  2   4    male\n",
      "2  3   3    male\n",
      "3  4   6  female\n",
      "\n",
      "After joining two dataframes\n",
      "   id_left          name id_right age  gender\n",
      "0       1          john        1   5    male\n",
      "1       2         jacob        2   4    male\n",
      "2       3  Jingleheimer        3   3    male\n",
      "3       4       Schmidt        4   6  female\n",
      "\n",
      "Based on the join operation new attributes from df2 are added horizontally. However we have duplicat ids\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john'], [2,'jacob'],[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "df2 = pd.DataFrame(np.array([[1, 5,'male'],[2, 4,'male'],[3, 3,'male'],[4, 6,'female']]),\n",
    "                  columns=['id','age','gender'])\n",
    "\n",
    "combined_df = df1.join(df2, lsuffix='_left', rsuffix='_right')\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "\n",
    "print('\\nAfter joining two dataframes\\n',combined_df)\n",
    "print('\\nBased on the join operation new attributes from df2 are added horizontally. However we have duplicat ids')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1\n",
      "   id          name\n",
      "0  1          john\n",
      "1  2         jacob\n",
      "2  3  Jingleheimer\n",
      "3  4       Schmidt\n",
      "\n",
      "df2\n",
      "   id age  gender\n",
      "0  1   5    male\n",
      "1  2   4    male\n",
      "2  3   3    male\n",
      "3  4   6  female\n",
      "\n",
      "After joining two dataframes\n",
      "   id          name age  gender\n",
      "0  1          john   5    male\n",
      "1  2         jacob   4    male\n",
      "2  3  Jingleheimer   3    male\n",
      "3  4       Schmidt   6  female\n",
      "\n",
      "Based on the join the new attributes from df2 are added horizontally. Also now we do not nave to worry about duplicate id\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([[1,'john'], [2,'jacob'],[3,'Jingleheimer'], [4,'Schmidt']]),\n",
    "                  columns=['id','name'])\n",
    "df2 = pd.DataFrame(np.array([[1, 5,'male'],[2, 4,'male'],[3, 3,'male'],[4, 6,'female']]),\n",
    "                  columns=['id','age','gender'])\n",
    "\n",
    "combined_df = df1.join(df2.set_index('id'), on ='id')\n",
    "print('\\ndf1\\n',df1)\n",
    "print('\\ndf2\\n',df2)\n",
    "\n",
    "print('\\nAfter joining two dataframes\\n',combined_df)\n",
    "print('\\nBased on the join the new attributes from df2 are added horizontally. Also now we do not nave to worry about duplicate id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Converting JSON to DataFrame</h1>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html\">pandas.read_json</a></p>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html\">pandas.io.json.json_normalize</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "      <th>Country</th>\n",
       "      <th>ShortName</th>\n",
       "      <th>OtherInfo.GovType</th>\n",
       "      <th>OtherInfo.HeadState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>12345</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NP</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>Prime Minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Morang</td>\n",
       "      <td>40000</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NP</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>Prime Minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sunsari</td>\n",
       "      <td>60000</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NP</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>Prime Minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>1234</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>UP</td>\n",
       "      <td>1337</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  population Country ShortName OtherInfo.GovType  \\\n",
       "0  Kathmandu       12345   Nepal        NP         Democracy   \n",
       "1     Morang       40000   Nepal        NP         Democracy   \n",
       "2    Sunsari       60000   Nepal        NP         Democracy   \n",
       "3      Bihar        1234   India        IN         Democracy   \n",
       "4         UP        1337   India        IN         Democracy   \n",
       "\n",
       "  OtherInfo.HeadState  \n",
       "0      Prime Minister  \n",
       "1      Prime Minister  \n",
       "2      Prime Minister  \n",
       "3           President  \n",
       "4           President  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "data = [{'Country': 'Nepal',\n",
    "          'ShortName': 'NP',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'Prime Minister'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Kathmandu', 'population': 12345},\n",
    "                      {'name': 'Morang', 'population': 40000},\n",
    "                      {'name': 'Sunsari', 'population': 60000}]},\n",
    "         {'Country': 'India',\n",
    "          'ShortName': 'IN',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'President'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Bihar', 'population': 1234},\n",
    "                       {'name': 'UP', 'population': 1337}]}]\n",
    "\n",
    "\n",
    "\n",
    "df = json_normalize(data, 'District/State/Province', ['Country', 'ShortName', \n",
    "                                                      ['OtherInfo', 'GovType'],\n",
    "                                                     ['OtherInfo', 'HeadState']])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Downloading saving .tgz (TAR) file</h1>\n",
    "<p><a href=\"https://docs.python.org/2/library/tarfile.html\">tarfile</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://www.website.com/...\"\n",
    "FILE_PATH = os.path.join(\"dataset\",\"folder\")\n",
    "FILE_URL = DOWNLOAD_ROOT + \"datasets/folder/file.tgz\"\n",
    "\n",
    "def fetch_data(file_url = FILE_URL, file_path = FILE_PATH):\n",
    "    if not os.path.isdir(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    tgz_path = os.path.join(file_path, \"file.tgz\")\n",
    "    urllib.request.urlretrieve(file_path, tgz_path)\n",
    "    file_tgz = tarfile.open(tgz_path)\n",
    "    file_tgz.extractall(path = file_path)\n",
    "    file_tgz.close()\n",
    "\n",
    "fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ordinal Encoding</h1>\n",
    "<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">sklearn.preprocessing.OrdinalEncoder</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "        name  population Country ShortName\n",
      "0  Kathmandu       12345   Nepal        NP\n",
      "1     Morang       40000   Nepal        NP\n",
      "2    Sunsari       60000   Nepal        NP\n",
      "3      Bihar        1234   India        IN\n",
      "4         UP        1337   India        IN\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "To add the encoded value to the existing dataframe...\n",
      "\n",
      "After \n",
      "        name  population Country ShortName  country_encoded\n",
      "0  Kathmandu       12345   Nepal        NP              1.0\n",
      "1     Morang       40000   Nepal        NP              1.0\n",
      "2    Sunsari       60000   Nepal        NP              1.0\n",
      "3      Bihar        1234   India        IN              0.0\n",
      "4         UP        1337   India        IN              0.0\n",
      "\n",
      "View encoced categories run ordinal_encoder.categories_\n",
      "\n",
      "[array(['India', 'Nepal'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "data = [{'Country': 'Nepal',\n",
    "          'ShortName': 'NP',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'Prime Minister'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Kathmandu', 'population': 12345},\n",
    "                      {'name': 'Morang', 'population': 40000},\n",
    "                      {'name': 'Sunsari', 'population': 60000}]},\n",
    "         {'Country': 'India',\n",
    "          'ShortName': 'IN',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'President'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Bihar', 'population': 1234},\n",
    "                       {'name': 'UP', 'population': 1337}]}]\n",
    "\n",
    "\n",
    "\n",
    "df = json_normalize(data, 'District/State/Province', ['Country', 'ShortName'])\n",
    "print('Before')\n",
    "print(df)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "encoded_data = ordinal_encoder.fit_transform(df[['Country']])\n",
    "print(encoded_data)\n",
    "\n",
    "# To add the encoded value to the existing dataframe...\n",
    "df_encoded = df.copy()\n",
    "df_encoded['country_encoded'] = encoded_data\n",
    "print('\\nAfter ')\n",
    "print(df_encoded)\n",
    "print('\\nView encoced categories run ordinal_encoder.categories_\\n')\n",
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Multiple column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Ordinal Encoding\n",
      "        name  population Country OtherInfo.GovType OtherInfo.HeadState\n",
      "0  Kathmandu       12345   Nepal         Democracy      Prime Minister\n",
      "1     Morang       40000   Nepal         Democracy      Prime Minister\n",
      "2    Sunsari       60000   Nepal         Democracy      Prime Minister\n",
      "3      Bihar        1234   India         Democracy           President\n",
      "4         UP        1337   India         Democracy           President\n",
      "\n",
      "Look to encode following categories ['Country', 'OtherInfo.GovType', 'OtherInfo.HeadState']\n",
      "[[1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "After\n",
      "        name  population Country OtherInfo.GovType OtherInfo.HeadState  \\\n",
      "0  Kathmandu       12345   Nepal         Democracy      Prime Minister   \n",
      "1     Morang       40000   Nepal         Democracy      Prime Minister   \n",
      "2    Sunsari       60000   Nepal         Democracy      Prime Minister   \n",
      "3      Bihar        1234   India         Democracy           President   \n",
      "4         UP        1337   India         Democracy           President   \n",
      "\n",
      "   Country_encoded  OtherInfo.GovType_encoded  OtherInfo.HeadState_encoded  \n",
      "0              1.0                        0.0                          1.0  \n",
      "1              1.0                        0.0                          1.0  \n",
      "2              1.0                        0.0                          1.0  \n",
      "3              0.0                        0.0                          0.0  \n",
      "4              0.0                        0.0                          0.0  \n",
      "\n",
      "View encoded categories\n",
      "[array(['India', 'Nepal'], dtype=object), array(['Democracy'], dtype=object), array(['President', 'Prime Minister'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data = [{'Country': 'Nepal',\n",
    "          'ShortName': 'NP',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'Prime Minister'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Kathmandu', 'population': 12345},\n",
    "                      {'name': 'Morang', 'population': 40000},\n",
    "                      {'name': 'Sunsari', 'population': 60000}]},\n",
    "         {'Country': 'India',\n",
    "          'ShortName': 'IN',\n",
    "          'OtherInfo': {\n",
    "               'GovType': 'Democracy',\n",
    "              'HeadState': 'President'\n",
    "          },\n",
    "          'District/State/Province': [{'name': 'Bihar', 'population': 1234},\n",
    "                       {'name': 'UP', 'population': 1337}]}]\n",
    "\n",
    "\n",
    "\n",
    "df = json_normalize(data, 'District/State/Province', ['Country', \n",
    "                                                      ['OtherInfo', 'GovType'],\n",
    "                                                     ['OtherInfo', 'HeadState']])\n",
    "print(\"Before Ordinal Encoding\")\n",
    "print(df)\n",
    "\n",
    "ordinal_cat = ['Country', 'OtherInfo.GovType', 'OtherInfo.HeadState']\n",
    "print('\\nLook to encode following categories', ordinal_cat)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "encoded_data = ordinal_encoder.fit_transform(df[ordinal_cat])\n",
    "print(encoded_data)\n",
    "# To add encoded value as seperate columns\n",
    "df_new_values = pd.DataFrame(encoded_data, columns= [str(ordinal_cat[i])+'_encoded' for i in range(len(ordinal_cat))])\n",
    "df_encoded = pd.concat([df,df_new_values], axis =1)\n",
    "print('\\nAfter')\n",
    "print(df_encoded)\n",
    "print('\\nView encoded categories')\n",
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age gender pass/fail\n",
      "0   John    5      m      fail\n",
      "1   Mary    2      f      pass\n",
      "2   Jane    5      f      fail\n",
      "3  Jacob    1      m      pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>pass/fail</th>\n",
       "      <th>Encoded_gender</th>\n",
       "      <th>Encoded_pass/fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>John</td>\n",
       "      <td>5</td>\n",
       "      <td>m</td>\n",
       "      <td>fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "      <td>fail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age gender pass/fail  Encoded_gender  Encoded_pass/fail\n",
       "0   John    5      m      fail             1.0                0.0\n",
       "1   Mary    2      f      pass             0.0                1.0\n",
       "2   Jane    5      f      fail             0.0                0.0\n",
       "3  Jacob    1      m      pass             1.0                1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data = {'name':['John', 'Mary', 'Jane', 'Jacob'],\n",
    "       'age': [5,2,5,1],\n",
    "       'gender': ['m','f','f','m'],\n",
    "       'pass/fail': ['fail','pass','fail','pass']}\n",
    "df = pd.DataFrame(data)\n",
    "df_cat = ['gender', 'pass/fail']\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "print(df)\n",
    "encoded_array = ordinal_encoder.fit_transform(df[df_cat])\n",
    "pd.concat([df, pd.DataFrame(encoded_array, columns = ['Encoded_'+str(df_cat[i]) for i in range(len(df_cat))])], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Null Values in DataFrame</h1>\n",
    "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html\">pandas.DataFrame.isna</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get count of Null Values in each columns in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age       born    name        toy\n",
      "0  5.0        NaT  Alfred       None\n",
      "1  6.0 1939-05-27  Batman  Batmobile\n",
      "2  NaN 1940-04-25              Joker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age     1\n",
       "born    1\n",
       "name    0\n",
       "toy     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
    "                   'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "                            pd.Timestamp('1940-04-25')],\n",
    "                   'name': ['Alfred', 'Batman', ''],\n",
    "                   'toy': [None, 'Batmobile', 'Joker']})\n",
    "print(df)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age gender pass/fail\n",
      "0   John    5      m      fail\n",
      "1   Mary    2      f      pass\n",
      "2   Jane    5      f      fail\n",
      "3  Jacob    1      m      pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = {'name':['John', 'Mary', 'Jane', 'Jacob'],\n",
    "       'age': [5,2,5,1],\n",
    "       'gender': ['m','f','f','m'],\n",
    "       'pass/fail': ['fail','pass','fail','pass']}\n",
    "df = pd.DataFrame(data)\n",
    "df_cat = ['gender', 'pass/fail']\n",
    "onehot_encoder = OneHotEncoder()\n",
    "print(df)\n",
    "encoded_array = onehot_encoder.fit_transform(df[df_cat])\n",
    "# pd.concat([df, pd.DataFrame(encoded_array, columns = ['Encoded_'+str(df_cat[i]) for i in range(len(df_cat))])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'm']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(onehot_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda expressions or Anonymous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# create a function to return square of a given number \n",
    "def square(a): # Define function name and paramenters. This case it takes one value idealy num\n",
    "    return a*a # intended operation. One expression or operation only \n",
    "x = 4 \n",
    "print(square(x)) # Run the square function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# Do the same (calculate square) using Lambda expresstion\n",
    "f = lambda x: x*x # create a function using lambda expression. THis only works when you intend to use one expression/calculation\n",
    "print(f(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "33\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# Lambda functions can be used inside another function. \n",
    "# create a function that give you quadruples of a given number\n",
    "def test(x): # Create function named test that takes in one input\n",
    "    return lambda a : a * x # this returns a lambda function with x's value set to whatever is passed. So if 1 is passed the output is a lambda expression (lambda x: x * 1)\n",
    "    # You can use this function to create other function that can give you double, triple, quadruple and so on. \n",
    "\n",
    "testdouble = test(2) # this sets the value of x to be 2. So when we call this function pass a number \"x\" we now get the output x * 2.\n",
    "testtriple = test(3) # this sets the value of x to be 3. So when we call this function pass a number \"x\" we now get the output x * 3.\n",
    "getquadruple = test(4) # this sets the value of x to be 4. So when we call this function pass a number \"x\" we now get the output x * 4.\n",
    "\n",
    "print(testdouble(11))\n",
    "print(testtriple(11))\n",
    "print(getquadruple(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id                   name age\n",
      "0  1           Mr. John Doe   5\n",
      "1  2        Dr. Jacob Jones   2\n",
      "2  3          Mrs. Jane Roe  25\n",
      "3  4  Master. Michael River  12\n",
      "Inspect the name column. Name consists of title, first and last name\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-97bfbdbe8721>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# df1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Use a lambda expression to seperate names using a delimitor (Title, Firstname, LastName)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.array([\n",
    "    [1,'Mr. John Doe',5], \n",
    "    [2,'Dr. Jacob Jones',2],\n",
    "    [3, 'Mrs. Jane Roe', 25],\n",
    "    [4,'Master. Michael River',12]]),\n",
    "                  columns=['id','name','age'])\n",
    "print(df1)\n",
    "print(\"Inspect the name column. Name consists of title, first and last name\")\n",
    "\n",
    "# Create a new column called title which consists of the title only. Use lambda expression to complet this task. do the same and seperate first and last name as well\n",
    "df1['title'] = df1[\"name\"].apply(lambda x : x.split()[0])\n",
    "df1['firstname'] = df1[\"name\"].apply(lambda x : x.split()[1])\n",
    "df1['lastname'] = df1[\"name\"].apply(lambda x : x.split()[2])\n",
    "df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', 'Binay', 'Raut']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Mr Binay Raut\"\n",
    "f = lambda x : x.split(' ')\n",
    "f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
